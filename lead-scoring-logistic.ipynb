{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set variables\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Define various helper functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_url(x):\n",
    "    if x != None:\n",
    "        return x.get('string_value').split('?')[0]\n",
    "    else:\n",
    "        return '(entrance)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_extract(x, target_str):\n",
    "    if x != None:\n",
    "        return x.get(target_str)\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Extract/Transform</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get GA4 data on relevant users from BQ\n",
    "ga4_df = pd.read_gbq(ga4_query_str, project_id=bq_project_str, credentials=bq_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga4_df = ga4_df.drop_duplicates(['user_pseudo_id', 'event_name', 'event_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GA4 has a lot of nested data in the schema, this pulls out the pieces we're interested in\n",
    "ga4_df['page_location'] = ga4_df['page_location'].apply(lambda x: extract_url(x))\n",
    "ga4_df['page_referrer'] = ga4_df['page_referrer'].apply(lambda x: extract_url(x))\n",
    "\n",
    "ga4_df['user_email'] = ga4_df['user_email'].apply(lambda x: cell_extract(x, 'string_value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga4_df['utm_campaign'] = ga4_df['traffic_source'].apply(lambda x: cell_extract(x, 'name'))\n",
    "ga4_df['utm_medium'] = ga4_df['traffic_source'].apply(lambda x: cell_extract(x, 'medium'))\n",
    "ga4_df['utm_source'] = ga4_df['traffic_source'].apply(lambda x: cell_extract(x, 'source'))\n",
    "\n",
    "ga4_df['form_id'] = ga4_df['form_id'].apply(lambda x: cell_extract(x, 'string_value'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize pages into groupings we're interested in\n",
    "ga4_df['booking_step'] = ''\n",
    "\n",
    "for step in url_category_dict.keys():\n",
    "    ga4_df['booking_step'] = np.where(ga4_df['page_location'].str.contains(url_category_dict.get(step)), step, ga4_df['booking_step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga4_df['event_name'] = np.where(ga4_df['event_name'] == 'generate_lead', ga4_df['event_name'] + '_' + ga4_df['form_id'], ga4_df['event_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga4_emails_df = ga4_df[ga4_df['user_email'].notnull()][['user_email', 'user_pseudo_id']].drop_duplicates('user_email')\n",
    "ga4_emails_dict = dict(zip(ga4_emails_df['user_pseudo_id'], ga4_emails_df['user_email']))\n",
    "ga4_df['user_email'] = ga4_df['user_pseudo_id'].apply(lambda x: ga4_emails_dict.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get HubSpot data on deal stages from our BigQuery clone\n",
    "hs_df = pd.read_gbq(hs_query_str, project_id=bq_project_str, credentials=bq_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns with binary indicators for if a deal became a purchase or qualified lead\n",
    "hs_df['purchase'] = np.where(hs_df['deal_pipeline_id'] == '13508273', 1, 0)\n",
    "\n",
    "hs_df['opportunity'] = np.where((hs_df['deal_opportunity_date'].notnull()\n",
    "                                 | hs_df['deal_priority_date'].notnull()\n",
    "                                 | hs_df['deal_followup_date'].notnull()), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Transform</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataframe with binary variables for user behavoir and outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_emails_list = list(ga4_df[ga4_df['user_email'].notnull()]['user_email'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "booking_page_list = list(ga4_df[ga4_df['booking_step'] != '']['booking_step'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_list = [x for x in list(ga4_df['event_name'].unique()) if x not in (session_stats_list + [np.nan, 'purchase'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_outcomes_df = pd.DataFrame()\n",
    "user_outcomes_df = pd.DataFrame(columns=(['property_email'] + session_stats_list + ['utm_source', 'utm_campaign'] + booking_page_list + event_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_outcomes_df['property_email'] = user_emails_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_outcomes_df = pd.merge(user_outcomes_df, hs_df[['property_email', 'opportunity', 'purchase']], \n",
    "                            how='left', on='property_email')\n",
    "\n",
    "display(len(user_outcomes_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(user_outcomes_df.index):\n",
    "    e = user_outcomes_df.loc[i, 'property_email']\n",
    "    _df = ga4_df[ga4_df['user_email'] == e]\n",
    "    \n",
    "    for booking_step in booking_page_list:\n",
    "        l = np.where(_df['booking_step'] == booking_step, 1, 0).sum()\n",
    "        user_outcomes_df.loc[i, booking_step] = l\n",
    "    \n",
    "    for event in (event_list + session_stats_list):\n",
    "        l = np.where(_df['event_name'] == event, 1, 0).sum()\n",
    "        user_outcomes_df.loc[i, event] = l\n",
    "            \n",
    "    s, c = _df[['utm_source', 'utm_campaign']][-1:].values[0]\n",
    "    user_outcomes_df.loc[i, 'utm_source'] = s\n",
    "    user_outcomes_df.loc[i, 'utm_campaign'] = c\n",
    "    \n",
    "for booking_step in booking_page_list:\n",
    "    user_outcomes_df[booking_step] = np.where(user_outcomes_df[booking_step] > 1, 1, 0)\n",
    "    \n",
    "for event in event_list:\n",
    "    user_outcomes_df[event] = np.where(user_outcomes_df[event] > 1, 1, 0)\n",
    "\n",
    "user_outcomes_df['session_start'] = user_outcomes_df['session_start'].astype('int64')\n",
    "user_outcomes_df['page_view'] = user_outcomes_df['page_view'].astype('int64')\n",
    "\n",
    "user_outcomes_df['pages/session'] = user_outcomes_df['page_view'] / user_outcomes_df['session_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_outcomes_df.replace(np.inf, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "user_outcomes_df[['session_start', 'page_view', 'pages/session']] = scaler.fit_transform(user_outcomes_df[['session_start', 'page_view', 'pages/session']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dummies_df = pd.get_dummies(user_outcomes_df['utm_source'])\n",
    "top_sources_list = list(source_dummies_df.sum().sort_values(ascending=False)[:10].index)\n",
    "source_dummies_df = source_dummies_df[top_sources_list]\n",
    "source_dummies_df.columns = ['source_' + x for x in list(source_dummies_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_dummies_df = pd.get_dummies(user_outcomes_df['utm_campaign'])\n",
    "top_campaigns_list = list(campaign_dummies_df.sum().sort_values(ascending=False)[:10].index)\n",
    "campaign_dummies_df = campaign_dummies_df[top_campaigns_list]\n",
    "campaign_dummies_df.columns = ['campaign_' + x for x in list(campaign_dummies_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_outcomes_df = user_outcomes_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_outcomes_df = pd.concat([user_outcomes_df, source_dummies_df, campaign_dummies_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 9))\n",
    "heatmap = sns.heatmap(user_outcomes_df.corr()[['opportunity', 'purchase']], vmin=-1, vmax=1, cmap='BrBG')\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize': 18}, pad=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_outcomes_df.corr()[['opportunity', 'purchase']].sort_values('opportunity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "153/4685"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Modeling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = user_outcomes_df.drop(['property_email', 'utm_source', 'utm_campaign', 'opportunity', 'purchase'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = user_outcomes_df['opportunity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, train_size=0.7, test_size=0.3, random_state=3892)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_df\n",
    "y_train = y_df\n",
    "\n",
    "y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.to_csv(r'x-train.csv')\n",
    "#X_test.to_csv(r'x-test.csv')\n",
    "#y_train.to_csv(r'y-train.csv')\n",
    "#y_test.to_csv(r'y-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = pd.read_csv(r'x-train.csv')\n",
    "#X_test = pd.read_csv(r'x-test.csv')\n",
    "#y_train = pd.read_csv(r'y-train.csv')\n",
    "#y_test = pd.read_csv(r'y-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 1 - All variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_m1_fitted = sm.Logit(y_train, X_train).fit(maxiter=100, method='ncg')\n",
    "logistic_m1_fitted.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Narrow variables with recursive factor elimination</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_log = LogisticRegression()\n",
    "rfe = RFE(sk_log, step=2)\n",
    "rfe = rfe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_cols = X_train.columns[rfe.support_]\n",
    "list(zip(X_train.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 2 - Variables Identified by RFE</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_m2_fitted = sm.Logit(y_train, X_train[predictor_cols]).fit(maxiter=100, method='powell')\n",
    "logistic_m2_fitted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_y_train_pred = logistic_m2_fitted.predict(X_train[predictor_cols])\n",
    "m2_y_train_pred = m2_y_train_pred.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_y_train_pred = pd.DataFrame(index=y_train.index, data={'opportunity-actual':y_train.values, 'model-prob':m2_y_train_pred})\n",
    "m2_y_train_pred['opportunity-model'] = m2_y_train_pred['model-prob'].apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(m2_y_train_pred['opportunity-actual'].sum())\n",
    "display(m2_y_train_pred['opportunity-model'].sum())\n",
    "m2_y_train_pred.sort_values('model-prob', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 3 - Web Events Only</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_event_cols = [x for x in list(X_train) if 'source_' not in x and 'campaign_' not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_m3_fitted = sm.Logit(y_train, X_train[web_event_cols]).fit(maxiter=100, method='ncg')\n",
    "logistic_m3_fitted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_y_train_pred = logistic_m3_fitted.predict(X_train[web_event_cols])\n",
    "m3_y_train_pred = m3_y_train_pred.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_y_train_pred = pd.DataFrame(index=y_train.index, data={'opportunity-actual':y_train.values, 'model-prob':m3_y_train_pred})\n",
    "m3_y_train_pred['opportunity-model'] = m3_y_train_pred['model-prob'].apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(m3_y_train_pred['opportunity-actual'].sum())\n",
    "display(m3_y_train_pred['opportunity-model'].sum())\n",
    "m3_y_train_pred.sort_values('model-prob', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Model 4 - Origins Only</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origins_cols = [x for x in list(X_train) if 'source_' in x or 'campaign_' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_m4_fitted = sm.Logit(y_train, X_train[origins_cols]).fit(maxiter=100, method='lbfgs')\n",
    "logistic_m4_fitted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_y_train_pred = logistic_m4_fitted.predict(X_train[origins_cols])\n",
    "m4_y_train_pred = m4_y_train_pred.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_y_train_pred = pd.DataFrame(index=y_train.index, data={'opportunity-actual':y_train.values, 'model-prob':m4_y_train_pred})\n",
    "m4_y_train_pred['opportunity-model'] = m4_y_train_pred['model-prob'].apply(lambda x: 1 if x > 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(m4_y_train_pred['opportunity-actual'].sum())\n",
    "display(m4_y_train_pred['opportunity-model'].sum())\n",
    "m4_y_train_pred.sort_values('model-prob', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['features'] = X_train[web_event_cols].columns\n",
    "vif['vif'] = [variance_inflation_factor(X_train[web_event_cols].values, i) for i in range(X_train[web_event_cols].shape[1])]\n",
    "vif['vif'] = round(vif['vif'], 2)\n",
    "vif = vif.sort_values(by = 'vif', ascending = False)\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
